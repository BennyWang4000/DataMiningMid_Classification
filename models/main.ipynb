{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import *\n",
    "import utils.df_processor as dfp\n",
    "import utils.word_segment as ws\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load original csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i = pd.read_csv(I_DATA_PATH, encoding=ENCODING)\n",
    "df_s = pd.read_csv(S_DATA_PATH, encoding=ENCODING)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add additional column for category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i.insert(0, 'category', '內科')\n",
    "df_s.insert(0, 'category', '外科')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concate two dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_i, df_s], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add additional column for compose category and department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(0, 'cat_dep', df['category']+df['department'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if column of ask is null, copy the context from title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['ask']== '无', 'ask']= df[df['ask']== '无']['title']\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_dep</th>\n",
       "      <th>dep_id</th>\n",
       "      <th>category</th>\n",
       "      <th>department</th>\n",
       "      <th>title</th>\n",
       "      <th>ask</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_clean</th>\n",
       "      <th>ask_clean</th>\n",
       "      <th>title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336590</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336591</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336592</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336593</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336594</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336595 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cat_dep  dep_id category department title  ask answer answer_clean  \\\n",
       "0          NaN     NaN      NaN        NaN   NaN  NaN    NaN          NaN   \n",
       "1          NaN     NaN      NaN        NaN   NaN  NaN    NaN          NaN   \n",
       "2          NaN     NaN      NaN        NaN   NaN  NaN    NaN          NaN   \n",
       "3          NaN     NaN      NaN        NaN   NaN  NaN    NaN          NaN   \n",
       "4          NaN     NaN      NaN        NaN   NaN  NaN    NaN          NaN   \n",
       "...        ...     ...      ...        ...   ...  ...    ...          ...   \n",
       "336590     NaN     NaN      NaN        NaN   NaN  NaN    NaN          NaN   \n",
       "336591     NaN     NaN      NaN        NaN   NaN  NaN    NaN          NaN   \n",
       "336592     NaN     NaN      NaN        NaN   NaN  NaN    NaN          NaN   \n",
       "336593     NaN     NaN      NaN        NaN   NaN  NaN    NaN          NaN   \n",
       "336594     NaN     NaN      NaN        NaN   NaN  NaN    NaN          NaN   \n",
       "\n",
       "       ask_clean title_clean  \n",
       "0            NaN         NaN  \n",
       "1            NaN         NaN  \n",
       "2            NaN         NaN  \n",
       "3            NaN         NaN  \n",
       "4            NaN         NaN  \n",
       "...          ...         ...  \n",
       "336590       NaN         NaN  \n",
       "336591       NaN         NaN  \n",
       "336592       NaN         NaN  \n",
       "336593       NaN         NaN  \n",
       "336594       NaN         NaN  \n",
       "\n",
       "[336595 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.where(df['ask']== '无'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40381\n"
     ]
    }
   ],
   "source": [
    "print((df['ask']== '无').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stop Words and Word Segment \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create cloumns to store result of word segmentation and removing stopwords \n",
    "\n",
    "speding time:\n",
    "- title: 6m 30.2s\n",
    "- ask: 9m 8.3s\n",
    "- ans: 14m 32.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['answer_clean'] = df['answer'].apply(lambda x: ws.word_segment(x, STOP_WORDS_PATH))\n",
    "df['ask_clean'] = df['ask'].apply(lambda x: ws.word_segment(x, STOP_WORDS_PATH))\n",
    "df['title_clean'] = df['title'].apply(lambda x: ws.word_segment(x, STOP_WORDS_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save csv after word segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(SAVING_DIR, 'df.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV After WS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ALL_DATA_PATH, encoding=ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_i['department'].value_counts())\n",
    "display(df_s['department'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "內科神经科      46844\n",
       "內科消化科      32245\n",
       "內科呼吸科      27931\n",
       "外科肛肠       24016\n",
       "外科神经脑外科    23620\n",
       "內科心血管科     22841\n",
       "內科内分泌科     21745\n",
       "外科普通外科     21179\n",
       "內科肝病科      20888\n",
       "外科泌尿科      18422\n",
       "內科肾内科      14010\n",
       "內科普通内科     13447\n",
       "內科血液科       9968\n",
       "外科肝胆科       8831\n",
       "外科乳腺科       8823\n",
       "外科血管科       6404\n",
       "內科风湿免疫科     5486\n",
       "內科感染科       4035\n",
       "外科胸外科       2913\n",
       "外科心外科       1777\n",
       "Name: cat_dep, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "df= dfp.df_filt(df, DEP_MIN_AMOUNT)\n",
    "display(dfp.get_dep_counts(df))\n",
    "print(len(dfp.get_dep_counts(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add additional column for class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_lst= ['內科内分泌科', '內科呼吸科', '內科心血管科', '內科感染科', '內科普通内科', '內科消化科', '內科神经科', '內科肝病科'\n",
    ", '內科肾内科', '內科血液科', '內科风湿免疫科', '外科乳腺科', '外科心外科', '外科普通外科', '外科泌尿科', '外科神经脑外科'\n",
    ", '外科肛肠', '外科肝胆科', '外科胸外科', '外科血管科']\n",
    "\n",
    "df.insert(1, 'dep_id', df['cat_dep'].apply(lambda x: dep_lst.index(x) if x in dep_lst else 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_dep</th>\n",
       "      <th>dep_id</th>\n",
       "      <th>category</th>\n",
       "      <th>department</th>\n",
       "      <th>title</th>\n",
       "      <th>ask</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_clean</th>\n",
       "      <th>ask_clean</th>\n",
       "      <th>title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>內科心血管科</td>\n",
       "      <td>2</td>\n",
       "      <td>內科</td>\n",
       "      <td>心血管科</td>\n",
       "      <td>高血压患者能吃党参吗？</td>\n",
       "      <td>我有高血压这两天女婿来的时候给我拿了些党参泡水喝，您好高血压可以吃党参吗？</td>\n",
       "      <td>高血压病人可以口服党参的。党参有降血脂，降血压的作用，可以彻底消除血液中的垃圾，从而对冠心病...</td>\n",
       "      <td>['高血压', '病人', '口服', '党参', '党参', '降血脂', '降血压', ...</td>\n",
       "      <td>['高血压', '两天', '女婿', '些', '党参', '泡水', '喝', '您好'...</td>\n",
       "      <td>['高血压', '患者', '吃', '党参']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>內科心血管科</td>\n",
       "      <td>2</td>\n",
       "      <td>內科</td>\n",
       "      <td>心血管科</td>\n",
       "      <td>高血压该治疗什么？</td>\n",
       "      <td>我是一位中学教师，平时身体健康，最近学校组织健康检查，结果发觉我是高血压，去年还没有这种情况...</td>\n",
       "      <td>高血压患者首先要注意控制食盐摄入量，每天不超过六克，注意不要吃太油腻的食物，多吃新鲜的绿色蔬...</td>\n",
       "      <td>['高血压', '患者', '控制', '食盐', '摄入量', '不', '超过', '六...</td>\n",
       "      <td>['一位', '中学教师', '平时', '身体健康', '学校', '组织', '健康检查...</td>\n",
       "      <td>['高血压', '治疗']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>內科心血管科</td>\n",
       "      <td>2</td>\n",
       "      <td>內科</td>\n",
       "      <td>心血管科</td>\n",
       "      <td>老年人高血压一般如何治疗？</td>\n",
       "      <td>我爷爷今年68了，年纪大了，高血压这些也领着来了，这些病让老人很痛苦，每次都要按时喝药，才能...</td>\n",
       "      <td>你爷爷患高血压，这是老年人常见的心血管病，血管老化硬化，血压调整能力消退了，目前治疗高血压最...</td>\n",
       "      <td>['爷爷', '患', '高血压', '这是', '老年人', '常见', '心血管病', ...</td>\n",
       "      <td>['爷爷', '68', '年纪', '大', '高血压', '领着', '病', '老人'...</td>\n",
       "      <td>['老年人', '高血压', '治疗']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>內科内分泌科</td>\n",
       "      <td>0</td>\n",
       "      <td>內科</td>\n",
       "      <td>内分泌科</td>\n",
       "      <td>糖尿病还会进行遗传吗？</td>\n",
       "      <td>糖尿病有隔代遗传吗？我妈是糖尿病，很多年了，也没养好，我现在也是，我妹子也是，我儿子现在二十...</td>\n",
       "      <td>2型糖尿病的隔代遗传概率为父母患糖尿病，临产的发生率为40%，比一般人患糖尿病，疾病，如何更...</td>\n",
       "      <td>['型', '糖尿病', '隔代遗传', '概率', '父母', '患', '糖尿病', '...</td>\n",
       "      <td>['糖尿病', '隔代遗传', '我妈', '糖尿病', '很多年', '没养', '好',...</td>\n",
       "      <td>['糖尿病', '还会', '遗传']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>內科内分泌科</td>\n",
       "      <td>0</td>\n",
       "      <td>內科</td>\n",
       "      <td>内分泌科</td>\n",
       "      <td>糖尿病一般需要怎么治疗？</td>\n",
       "      <td>我妈定期检查仔细检查的时候，仔细检查出患糖尿病，糖尿病需要有怎么治疗？我大概知晓是需要有控制...</td>\n",
       "      <td>糖尿病患者首先通过饮食控制和锻练运动，肥胖患者把体重降下来等方式调整一下看一看，如果血糖仍然...</td>\n",
       "      <td>['糖尿病', '患者', '饮食', '控制', '锻练', '运动', '肥胖', '患...</td>\n",
       "      <td>['我妈', '定期检查', '仔细检查', '仔细检查', '出患', '糖尿病', '糖...</td>\n",
       "      <td>['糖尿病', '治疗']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat_dep  dep_id category department          title  \\\n",
       "0  內科心血管科       2       內科       心血管科    高血压患者能吃党参吗？   \n",
       "1  內科心血管科       2       內科       心血管科      高血压该治疗什么？   \n",
       "2  內科心血管科       2       內科       心血管科  老年人高血压一般如何治疗？   \n",
       "3  內科内分泌科       0       內科       内分泌科    糖尿病还会进行遗传吗？   \n",
       "4  內科内分泌科       0       內科       内分泌科   糖尿病一般需要怎么治疗？   \n",
       "\n",
       "                                                 ask  \\\n",
       "0              我有高血压这两天女婿来的时候给我拿了些党参泡水喝，您好高血压可以吃党参吗？   \n",
       "1  我是一位中学教师，平时身体健康，最近学校组织健康检查，结果发觉我是高血压，去年还没有这种情况...   \n",
       "2  我爷爷今年68了，年纪大了，高血压这些也领着来了，这些病让老人很痛苦，每次都要按时喝药，才能...   \n",
       "3  糖尿病有隔代遗传吗？我妈是糖尿病，很多年了，也没养好，我现在也是，我妹子也是，我儿子现在二十...   \n",
       "4  我妈定期检查仔细检查的时候，仔细检查出患糖尿病，糖尿病需要有怎么治疗？我大概知晓是需要有控制...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  高血压病人可以口服党参的。党参有降血脂，降血压的作用，可以彻底消除血液中的垃圾，从而对冠心病...   \n",
       "1  高血压患者首先要注意控制食盐摄入量，每天不超过六克，注意不要吃太油腻的食物，多吃新鲜的绿色蔬...   \n",
       "2  你爷爷患高血压，这是老年人常见的心血管病，血管老化硬化，血压调整能力消退了，目前治疗高血压最...   \n",
       "3  2型糖尿病的隔代遗传概率为父母患糖尿病，临产的发生率为40%，比一般人患糖尿病，疾病，如何更...   \n",
       "4  糖尿病患者首先通过饮食控制和锻练运动，肥胖患者把体重降下来等方式调整一下看一看，如果血糖仍然...   \n",
       "\n",
       "                                        answer_clean  \\\n",
       "0  ['高血压', '病人', '口服', '党参', '党参', '降血脂', '降血压', ...   \n",
       "1  ['高血压', '患者', '控制', '食盐', '摄入量', '不', '超过', '六...   \n",
       "2  ['爷爷', '患', '高血压', '这是', '老年人', '常见', '心血管病', ...   \n",
       "3  ['型', '糖尿病', '隔代遗传', '概率', '父母', '患', '糖尿病', '...   \n",
       "4  ['糖尿病', '患者', '饮食', '控制', '锻练', '运动', '肥胖', '患...   \n",
       "\n",
       "                                           ask_clean               title_clean  \n",
       "0  ['高血压', '两天', '女婿', '些', '党参', '泡水', '喝', '您好'...  ['高血压', '患者', '吃', '党参']  \n",
       "1  ['一位', '中学教师', '平时', '身体健康', '学校', '组织', '健康检查...             ['高血压', '治疗']  \n",
       "2  ['爷爷', '68', '年纪', '大', '高血压', '领着', '病', '老人'...      ['老年人', '高血压', '治疗']  \n",
       "3  ['糖尿病', '隔代遗传', '我妈', '糖尿病', '很多年', '没养', '好',...       ['糖尿病', '还会', '遗传']  \n",
       "4  ['我妈', '定期检查', '仔细检查', '仔细检查', '出患', '糖尿病', '糖...             ['糖尿病', '治疗']  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ALL_DATA_PATH, encoding=ENCODING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(6, 'title_clean', df['title'].apply(lambda x: ws.word_segment(x)))\n",
    "df.to_csv(os.path.join(SAVING_DIR, 'df_3.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split for train_set and test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test= train_test_split(df['ask_clean'], df['dep_id'], test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trun String to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "x_train= [literal_eval(lst) for lst in x_train]\n",
    "x_test= [literal_eval(lst) for lst in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['患者',\n",
       " '性别',\n",
       " '女患者',\n",
       " '年龄',\n",
       " '60',\n",
       " '肝硬化',\n",
       " '脾脏',\n",
       " '切除',\n",
       " '手术',\n",
       " '一个多月',\n",
       " '后',\n",
       " '发烧',\n",
       " '现象',\n",
       " '何原因',\n",
       " '服用',\n",
       " '药']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx= 0\n",
    "display(x_train[idx], y_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sklearn_api.gensim_word2vec import GensimWord2VecVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "xgb_model= Pipeline([\n",
    "    ('w2v', GensimWord2VecVectorizer(size=VECTOR_SIZE,\n",
    "        min_count=MIN_COUNT, \n",
    "        workers=WORKERS, \n",
    "        window=WINDOW)),\n",
    "    ('xgb', XGBClassifier(\n",
    "        learning_rate=LEARNING_RATE, \n",
    "        objective=OBJECTIVE, \n",
    "        eval_metric=EVAL_METRIC, \n",
    "        scale_pos_weight=SCALE_POS_WEIGHT, \n",
    "        colsample_btree=COLSAMPLE_BTREE,\n",
    "        subsample=SUBSAMPLE))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "xgb_model.fit(x_train, y_train)\n",
    "\n",
    "y_test_pred = xgb_model.predict(x_test)\n",
    "test_score = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "### model evaluate\n",
    "accuracy = accuracy_score(y_test,y_test_pred)\n",
    "print(\"accuarcy: %.5f%%\" % (accuracy*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save pipeline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "joblib.dump(xgb_model, os.path.join(SAVING_DIR, 'xgb_model.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:57:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[15:57:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[15:57:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot  as plt\n",
    "model_path = 'G:\\\\我的雲端硬碟\\\\xgb_model_68.joblib'\n",
    "xgb_pipeline = joblib.load(model_path)\n",
    "xgb_layer = xgb_pipeline.named_steps[\"xgb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XGBModel' object has no attribute 'callbacks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\CodeRepositories\\py_project\\data_mining\\DataMiningMid_Classification\\models\\main.ipynb Cell 49'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/CodeRepositories/py_project/data_mining/DataMiningMid_Classification/models/main.ipynb#ch0000061?line=0'>1</a>\u001b[0m yhat \u001b[39m=\u001b[39m xgb_pipeline\u001b[39m.\u001b[39;49mpredict(x_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CodeRepositories/py_project/data_mining/DataMiningMid_Classification/models/main.ipynb#ch0000061?line=1'>2</a>\u001b[0m score \u001b[39m=\u001b[39m accuracy_score(y_test, yhat)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CodeRepositories/py_project/data_mining/DataMiningMid_Classification/models/main.ipynb#ch0000061?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m%.5f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m score)\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anoconda\\envs\\nursing-env\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:113\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/sklearn/utils/metaestimators.py?line=109'>110</a>\u001b[0m         \u001b[39mraise\u001b[39;00m attr_err\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/sklearn/utils/metaestimators.py?line=111'>112</a>\u001b[0m     \u001b[39m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/sklearn/utils/metaestimators.py?line=112'>113</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(obj, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# noqa\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/sklearn/utils/metaestimators.py?line=113'>114</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/sklearn/utils/metaestimators.py?line=115'>116</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mfn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anoconda\\envs\\nursing-env\\lib\\site-packages\\sklearn\\pipeline.py:470\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/sklearn/pipeline.py?line=467'>468</a>\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/sklearn/pipeline.py?line=468'>469</a>\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39mtransform(Xt)\n\u001b[1;32m--> <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/sklearn/pipeline.py?line=469'>470</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msteps[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpredict(Xt, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpredict_params)\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anoconda\\envs\\nursing-env\\lib\\site-packages\\xgboost\\sklearn.py:1434\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1424'>1425</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1425'>1426</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1426'>1427</a>\u001b[0m     X: ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1431'>1432</a>\u001b[0m     iteration_range: Optional[Tuple[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1432'>1433</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1433'>1434</a>\u001b[0m     class_probs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1434'>1435</a>\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1435'>1436</a>\u001b[0m         output_margin\u001b[39m=\u001b[39;49moutput_margin,\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1436'>1437</a>\u001b[0m         ntree_limit\u001b[39m=\u001b[39;49mntree_limit,\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1437'>1438</a>\u001b[0m         validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1438'>1439</a>\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1439'>1440</a>\u001b[0m         iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1440'>1441</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1441'>1442</a>\u001b[0m     \u001b[39mif\u001b[39;00m output_margin:\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1442'>1443</a>\u001b[0m         \u001b[39m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1443'>1444</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m class_probs\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anoconda\\envs\\nursing-env\\lib\\site-packages\\xgboost\\sklearn.py:1047\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1042'>1043</a>\u001b[0m iteration_range \u001b[39m=\u001b[39m _convert_ntree_limit(\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1043'>1044</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_booster(), ntree_limit, iteration_range\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1044'>1045</a>\u001b[0m )\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1045'>1046</a>\u001b[0m iteration_range \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_iteration_range(iteration_range)\n\u001b[1;32m-> <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1046'>1047</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_can_use_inplace_predict():\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1047'>1048</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1048'>1049</a>\u001b[0m         predts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_booster()\u001b[39m.\u001b[39minplace_predict(\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1049'>1050</a>\u001b[0m             data\u001b[39m=\u001b[39mX,\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1050'>1051</a>\u001b[0m             iteration_range\u001b[39m=\u001b[39miteration_range,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1054'>1055</a>\u001b[0m             validate_features\u001b[39m=\u001b[39mvalidate_features,\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1055'>1056</a>\u001b[0m         )\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anoconda\\envs\\nursing-env\\lib\\site-packages\\xgboost\\sklearn.py:983\u001b[0m, in \u001b[0;36mXGBModel._can_use_inplace_predict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=977'>978</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_can_use_inplace_predict\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=978'>979</a>\u001b[0m     \u001b[39m# When predictor is explicitly set, using `inplace_predict` might result into\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=979'>980</a>\u001b[0m     \u001b[39m# error with incompatible data type.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=980'>981</a>\u001b[0m     \u001b[39m# Inplace predict doesn't handle as many data types as DMatrix, but it's\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=981'>982</a>\u001b[0m     \u001b[39m# sufficient for dask interface where input is simpiler.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=982'>983</a>\u001b[0m     predictor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_params()\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mpredictor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=983'>984</a>\u001b[0m     \u001b[39mif\u001b[39;00m predictor \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbooster \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgblinear\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=984'>985</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anoconda\\envs\\nursing-env\\lib\\site-packages\\xgboost\\sklearn.py:636\u001b[0m, in \u001b[0;36mXGBModel.get_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=633'>634</a>\u001b[0m cp \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mcopy(\u001b[39mself\u001b[39m)\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=634'>635</a>\u001b[0m cp\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m \u001b[39m=\u001b[39m cp\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__bases__\u001b[39m[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=635'>636</a>\u001b[0m params\u001b[39m.\u001b[39mupdate(cp\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49mget_params(cp, deep))\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=636'>637</a>\u001b[0m \u001b[39m# if kwargs is a dict, update params accordingly\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=637'>638</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkwargs\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39mdict\u001b[39m):\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anoconda\\envs\\nursing-env\\lib\\site-packages\\xgboost\\sklearn.py:633\u001b[0m, in \u001b[0;36mXGBModel.get_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=625'>626</a>\u001b[0m \u001b[39m\"\"\"Get parameters.\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=626'>627</a>\u001b[0m \u001b[39m# Based on: https://stackoverflow.com/questions/59248211\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=627'>628</a>\u001b[0m \u001b[39m# The basic flow in `get_params` is:\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=628'>629</a>\u001b[0m \u001b[39m# 0. Return parameters in subclass first, by using inspect.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=629'>630</a>\u001b[0m \u001b[39m# 1. Return parameters in `XGBModel` (the base class).\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=630'>631</a>\u001b[0m \u001b[39m# 2. Return whatever in `**kwargs`.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=631'>632</a>\u001b[0m \u001b[39m# 3. Merge them.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=632'>633</a>\u001b[0m params \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mget_params(deep)\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=633'>634</a>\u001b[0m cp \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mcopy(\u001b[39mself\u001b[39m)\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=634'>635</a>\u001b[0m cp\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m \u001b[39m=\u001b[39m cp\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__bases__\u001b[39m[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anoconda\\envs\\nursing-env\\lib\\site-packages\\sklearn\\base.py:210\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/sklearn/base.py?line=207'>208</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/sklearn/base.py?line=208'>209</a>\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_param_names():\n\u001b[1;32m--> <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/sklearn/base.py?line=209'>210</a>\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, key)\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/sklearn/base.py?line=210'>211</a>\u001b[0m     \u001b[39mif\u001b[39;00m deep \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(value, \u001b[39m\"\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/sklearn/base.py?line=211'>212</a>\u001b[0m         deep_items \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mget_params()\u001b[39m.\u001b[39mitems()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'XGBModel' object has no attribute 'callbacks'"
     ]
    }
   ],
   "source": [
    "yhat = xgb_pipeline.predict(x_test)\n",
    "score = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.5f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "No evaluation result, `eval_set` is not used during training.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\CodeRepositories\\py_project\\data_mining\\DataMiningMid_Classification\\models\\main.ipynb Cell 49'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/CodeRepositories/py_project/data_mining/DataMiningMid_Classification/models/main.ipynb#ch0000060?line=0'>1</a>\u001b[0m results \u001b[39m=\u001b[39m xgb_layer\u001b[39m.\u001b[39;49mevals_result()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CodeRepositories/py_project/data_mining/DataMiningMid_Classification/models/main.ipynb#ch0000060?line=1'>2</a>\u001b[0m \u001b[39m# plot learning curves\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CodeRepositories/py_project/data_mining/DataMiningMid_Classification/models/main.ipynb#ch0000060?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(results[\u001b[39m'\u001b[39m\u001b[39mvalidation_0\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlogloss\u001b[39m\u001b[39m'\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anoconda\\envs\\nursing-env\\lib\\site-packages\\xgboost\\sklearn.py:1140\u001b[0m, in \u001b[0;36mXGBModel.evals_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1137'>1138</a>\u001b[0m     evals_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevals_result_\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1138'>1139</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1139'>1140</a>\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1140'>1141</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo evaluation result, `eval_set` is not used during training.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1141'>1142</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///d%3A/ProgramFiles/Anoconda/envs/nursing-env/lib/site-packages/xgboost/sklearn.py?line=1143'>1144</a>\u001b[0m \u001b[39mreturn\u001b[39;00m evals_result\n",
      "\u001b[1;31mXGBoostError\u001b[0m: No evaluation result, `eval_set` is not used during training."
     ]
    }
   ],
   "source": [
    "results = xgb_layer.evals_result()\n",
    "# plot learning curves\n",
    "plt.plot(results['validation_0']['logloss'], label='train')\n",
    "plt.plot(results['validation_1']['logloss'], label='test')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa89559b8019c6b8d86cbf7b237623aaefbbcd820bdcd84fbfac8728b8f219a1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('nursing-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
